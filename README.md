# Bandit-Algorithms

This is a repository for educational materials to help learn about 
multi-arm bandits, or bandit algorithms. 

This repo builds off 
of the wonderful book [Bandit Algorithms](https://tor-lattimore.com/downloads/book/book.pdf),
graciously published for free online 
by Tor Lattimore and Csaba Szepesv√°ri.

If you have any questions or concerns, feel free to reach out to me,
Hunter Heidenreich, at hsh28 [ at ] drexel.edu

## Accompanying Materials

In order to study, understand, and discuss the material in the text,
the following is a collection of resources that I've put together. 
As always, if you find any issues let me know!

PDFs
- [Chapter 0: Bandit Algorithms - A Roadmap](PDFs/Chp0.pdf)
    - This is a presentation breaking down what I've come to find are the pertinent questions about bandit algorithm
    problems and how I've begun to map the really cool literature space of multi-arm bandits.
- [Chapter 4: Stochastic Bandits](PDFs/Chp4.pdf)
    - This is a presentation that breaks down Chapter 4 of the text, extracting what I've thought is the 
    "mission critical" aspects of what one needs to understand!

Jupyter Notebooks
- [Selected Problems from Chapter 4](chapters/04/SolvedProblems.ipynb)
    - This notebook encompasses a subset of the problems from Chapter 4 that involve experimentation and visualization 
    of said experiments.

### Outline

The following is a collection of Jupyter Notebooks that I've constructed while 
reading through the Bandit Algorithms text. 
If you find any issues or typos or any other concerns, feel free to let me know!
 
- Chapter 1: Introduction - [Jupyter Notebook](chapters/01/0-intro.ipynb)
- Chapter 4: Stochastic Bandits - [Jupyter Notebook](chapters/04/0-stochastics.ipynb)
- Chapter 6: The Explore-Then-Commit (ETC) Algorithm - [Jupyter Notebook](chapters/06/0-ETC.ipynb)
